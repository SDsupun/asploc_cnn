{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project ASPLOC - 1DT109 11201 (2024HT)\n",
    "#### By Supun Madusanka\n",
    "\n",
    "This script will use the LeNet NN architecture and quantize it to be used on hardware accelerator\n",
    "\n",
    "Ref:\n",
    "- [PyTorch tutorial on NN](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)\n",
    "- [PyTorch tutorial on NN pruning](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html)\n",
    "- [CNN](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)\n",
    "- [NN quantization](https://towardsdatascience.com/introduction-to-weight-quantization-2494701b9c0c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requried libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "DOWNLOAD_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset and preprocessing\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                            train = True,\n",
    "                                            transform = transforms.Compose([\n",
    "                                                    transforms.Resize((32,32)),\n",
    "                                                    transforms.ToTensor()\n",
    "                                                #     ,\n",
    "                                                #     transforms.Normalize(mean = (0.1307,), std = (0.3081,))\n",
    "                                                    ]),\n",
    "                                            download = DOWNLOAD_DATA)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                            train = False,\n",
    "                                            transform = transforms.Compose([\n",
    "                                                    transforms.Resize((32,32)),\n",
    "                                                    transforms.ToTensor()\n",
    "                                                #     ,\n",
    "                                                #     transforms.Normalize(mean = (0.1325,), std = (0.3105,))\n",
    "                                                    ]),\n",
    "                                            download=DOWNLOAD_DATA)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                            batch_size = batch_size,\n",
    "                                            shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a model with PyTorch\n",
    "==============\n",
    "\n",
    "In this tutorial, we use the\n",
    "[LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf) architecture\n",
    "from LeCun et al., 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square conv kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet().to(device=device)\n",
    "\n",
    "#Setting the loss function\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "#Setting the optimizer with the model parameters and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#this is defined to print how many steps are remaining when training\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [400/938], Loss: 0.0026\n",
      "Epoch [1/10], Step [800/938], Loss: 0.0031\n",
      "Epoch [2/10], Step [400/938], Loss: 0.0042\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0404\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0002\n",
      "Epoch [3/10], Step [800/938], Loss: 0.0875\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0004\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0002\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0009\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0058\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0043\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0001\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0051\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0006\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0001\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0203\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0006\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0004\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0158\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = cost(outputs, labels)\n",
    "        #Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 400 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    ".format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 99.01 %\n"
     ]
    }
   ],
   "source": [
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('conv1.weight', Parameter containing:\n",
      "tensor([[[[ 7.2516e-02,  5.2665e-02, -3.8219e-03,  2.0556e-01, -1.3547e-01],\n",
      "          [-6.7008e-02,  2.4579e-01,  4.5050e-01,  3.0839e-01,  1.2236e-01],\n",
      "          [-9.0664e-02, -1.4577e-01,  1.7678e-01,  3.5698e-01,  1.4170e-01],\n",
      "          [-1.7582e-01, -2.7391e-01, -2.9852e-01,  8.4123e-02,  7.4193e-02],\n",
      "          [-3.0596e-01, -2.9633e-01, -1.4885e-01, -1.9747e-01, -1.9624e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0369e-01,  1.6104e-01,  2.2792e-01,  2.3089e-02,  1.4041e-01],\n",
      "          [ 7.5471e-02,  3.0492e-01,  1.9584e-01,  1.2743e-01,  4.0496e-02],\n",
      "          [ 2.0146e-01,  1.0262e-01, -5.0157e-02,  3.4336e-02, -1.6055e-01],\n",
      "          [-2.5590e-01, -1.7346e-01, -3.7317e-01, -1.1355e-01, -1.4698e-01],\n",
      "          [-4.6209e-01, -3.9947e-01, -1.9265e-01, -9.4197e-02,  1.6645e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1350e-02, -2.5138e-01,  3.7261e-02,  5.5104e-02,  2.9144e-01],\n",
      "          [-3.0489e-01, -4.2895e-02, -1.2456e-01,  7.5359e-02,  2.8774e-01],\n",
      "          [-1.5446e-01, -2.4367e-01,  2.5077e-01,  1.8814e-01,  3.7286e-02],\n",
      "          [-2.9178e-01, -2.3939e-02,  1.3689e-01,  3.4630e-01, -1.0834e-01],\n",
      "          [-5.8959e-03, -1.5043e-01,  1.5581e-01,  1.3023e-01, -1.8961e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5754e-01, -3.0234e-02, -1.6611e-02,  2.0046e-01,  1.1028e-01],\n",
      "          [-8.8622e-02, -1.0631e-01,  7.0776e-02,  1.3824e-01, -2.0626e-03],\n",
      "          [-5.9699e-02, -5.8031e-02,  7.6707e-02,  1.8703e-01, -1.0693e-01],\n",
      "          [ 1.1794e-01,  1.4873e-01,  2.2714e-01,  2.4724e-02,  1.4007e-02],\n",
      "          [ 1.0896e-01,  1.2683e-01,  9.1437e-03,  2.3297e-02, -2.2065e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.0496e-02,  2.5508e-02, -1.9986e-01, -3.1346e-01,  3.7395e-02],\n",
      "          [-3.0738e-02, -2.3592e-01, -1.0953e-01,  1.6368e-01,  1.0362e-01],\n",
      "          [-1.7978e-02,  1.6167e-01,  3.1724e-01,  2.3891e-01,  2.9320e-01],\n",
      "          [-3.9650e-02,  2.3201e-01,  1.3244e-01, -9.7652e-02, -1.9684e-01],\n",
      "          [-5.4020e-02,  1.0044e-01, -2.7139e-01, -3.9840e-03, -1.9679e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.1656e-02,  9.0304e-02, -1.5111e-01, -1.1011e-01, -2.2999e-01],\n",
      "          [-8.5504e-03, -6.0753e-02, -6.8572e-02, -2.9294e-01, -7.2488e-02],\n",
      "          [ 1.5644e-01,  1.9252e-01,  3.3483e-01, -1.4909e-01, -2.2091e-01],\n",
      "          [-2.2250e-01,  2.3461e-01,  2.1456e-01,  2.2973e-01,  1.8151e-01],\n",
      "          [-1.4815e-02, -2.0310e-01,  1.0801e-01,  1.2296e-01, -2.0277e-02]]]],\n",
      "       requires_grad=True)), ('conv1.bias', Parameter containing:\n",
      "tensor([ 0.0404,  0.2037, -0.1281, -0.0932, -0.0544, -0.0411],\n",
      "       requires_grad=True)), ('conv2.weight', Parameter containing:\n",
      "tensor([[[[-1.2018e-01, -1.1878e-01, -1.1202e-01,  1.2780e-01,  3.0507e-01],\n",
      "          [-3.7174e-02,  1.5939e-01,  7.7389e-02, -1.2604e-01,  8.8878e-02],\n",
      "          [ 3.6647e-02,  2.1918e-01,  2.7514e-01,  8.1431e-02, -5.0106e-02],\n",
      "          [-3.7912e-02, -3.8090e-02, -7.7363e-02, -1.7811e-01,  2.6191e-02],\n",
      "          [-1.7965e-01, -1.9844e-01, -5.8797e-02, -2.9765e-02, -1.4767e-01]],\n",
      "\n",
      "         [[ 3.7469e-02,  1.1787e-02, -8.9753e-02, -1.1404e-02,  8.2697e-02],\n",
      "          [ 6.8270e-02,  7.3602e-02, -1.1650e-01, -1.6902e-01, -2.6216e-01],\n",
      "          [-7.6421e-02, -9.1196e-03,  4.9975e-02, -1.9443e-01, -4.6316e-01],\n",
      "          [ 3.8634e-02, -5.0920e-02, -2.3378e-01, -9.4016e-02,  9.7241e-02],\n",
      "          [-3.5933e-02, -1.5105e-01,  4.6559e-02,  4.2497e-02,  2.4123e-02]],\n",
      "\n",
      "         [[-3.7353e-02, -1.8980e-01,  1.9126e-03,  1.0326e-01,  3.3712e-03],\n",
      "          [-1.0556e-01, -1.8775e-01, -2.3054e-01, -2.9200e-01, -8.1357e-02],\n",
      "          [ 1.2463e-01,  4.0934e-02, -1.8451e-01, -1.2420e-01,  3.8031e-02],\n",
      "          [ 4.8518e-02, -5.0635e-02,  1.7649e-01,  1.8573e-01, -3.2710e-02],\n",
      "          [ 5.0032e-02,  1.6037e-01,  2.0366e-01,  1.6965e-01,  5.1643e-02]],\n",
      "\n",
      "         [[-1.0004e-01, -1.4177e-01, -6.5791e-02, -3.9583e-02, -2.0731e-01],\n",
      "          [-2.6529e-02, -3.1980e-02, -4.8784e-02,  6.7877e-02, -3.7632e-02],\n",
      "          [-3.9226e-03, -3.2493e-02, -4.5123e-02, -9.1966e-02, -1.0774e-02],\n",
      "          [ 2.6225e-02,  2.1487e-02,  1.7128e-01,  1.1547e-01, -4.5582e-02],\n",
      "          [ 5.2519e-02,  2.2005e-01,  1.5880e-01, -6.4548e-02, -2.2376e-01]],\n",
      "\n",
      "         [[ 6.1805e-02, -1.1381e-01,  3.7517e-02,  6.3598e-02, -9.7660e-02],\n",
      "          [-1.1064e-01, -4.8686e-02,  6.4891e-02,  1.5295e-02, -1.3417e-01],\n",
      "          [ 7.3538e-02,  8.4928e-02, -1.1841e-01, -3.8463e-02,  1.6626e-01],\n",
      "          [ 1.0400e-01, -8.6150e-02,  3.3800e-02,  1.7781e-01,  4.3948e-02],\n",
      "          [ 1.6131e-01,  2.5476e-01,  2.0138e-01,  7.6054e-02, -3.1185e-01]],\n",
      "\n",
      "         [[-3.7999e-02,  9.9663e-02,  8.0749e-02, -3.2813e-01, -2.2030e-01],\n",
      "          [-1.0030e-01,  2.0542e-01,  2.8569e-01,  9.8979e-02, -9.6692e-02],\n",
      "          [ 7.1516e-02, -8.7865e-02,  3.3607e-02,  2.1202e-01,  3.2202e-02],\n",
      "          [ 3.7757e-02, -1.1709e-02,  1.8299e-02, -4.1207e-02, -6.8600e-02],\n",
      "          [ 1.5014e-02, -1.4420e-01, -1.2307e-01, -1.7040e-01, -6.2929e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5403e-02,  7.9908e-02, -1.0633e-01, -1.0663e-01,  2.9189e-02],\n",
      "          [-1.0366e-02,  1.1831e-01,  5.7491e-02, -2.7326e-01, -1.4213e-01],\n",
      "          [-8.7006e-02,  1.6477e-01,  2.1992e-01, -3.4543e-02, -1.6021e-01],\n",
      "          [-8.4384e-02,  1.4298e-02,  2.1990e-01,  2.6917e-01, -5.0296e-02],\n",
      "          [-2.0966e-01, -2.3794e-01, -6.6444e-02,  1.5377e-01,  5.7515e-03]],\n",
      "\n",
      "         [[-4.7503e-02, -4.7956e-02, -2.4857e-01, -5.9181e-02,  2.4890e-01],\n",
      "          [ 8.0654e-02, -1.9575e-02, -2.6769e-01, -3.7741e-01, -6.5033e-02],\n",
      "          [-8.0517e-02,  3.8496e-02, -1.0187e-01, -2.0391e-01, -2.9460e-01],\n",
      "          [-2.3575e-02, -1.2895e-01,  4.7428e-02,  2.2787e-02, -1.0004e-01],\n",
      "          [ 8.8299e-02, -9.3184e-02,  4.9689e-04,  4.1007e-02,  3.9722e-02]],\n",
      "\n",
      "         [[ 2.8046e-02, -2.8845e-02, -1.7369e-02,  1.3479e-02,  5.6144e-02],\n",
      "          [-2.5014e-02, -9.7002e-02, -2.4224e-02, -2.4433e-01, -4.9857e-02],\n",
      "          [ 5.2909e-02, -1.8774e-01, -2.9000e-01, -1.7605e-01, -1.5828e-01],\n",
      "          [-6.1338e-02,  7.0209e-02, -1.8544e-02, -1.2526e-01, -1.6677e-01],\n",
      "          [ 7.8820e-02,  1.0182e-01,  1.7488e-02,  1.5685e-01,  2.1229e-02]],\n",
      "\n",
      "         [[ 1.9244e-01,  9.1582e-02,  1.6532e-01,  3.1649e-02, -6.9554e-02],\n",
      "          [ 1.3347e-01,  8.5479e-02, -6.6111e-02, -2.8562e-02,  1.0263e-01],\n",
      "          [ 5.4188e-02, -7.5613e-03, -5.0058e-03, -6.1789e-02,  1.1054e-01],\n",
      "          [ 3.7425e-03, -4.5521e-02, -6.0451e-02,  4.0142e-02,  4.7006e-02],\n",
      "          [-9.3279e-02, -1.5695e-02, -1.0517e-01,  4.9961e-02,  4.0697e-03]],\n",
      "\n",
      "         [[ 6.1719e-02,  1.8791e-03,  2.1273e-01,  2.9228e-01,  5.8366e-02],\n",
      "          [ 1.3213e-01,  2.8373e-02, -4.2302e-02,  7.0918e-03,  1.1594e-02],\n",
      "          [ 4.7378e-02, -1.5327e-01, -1.3139e-01, -3.7630e-02,  2.9709e-02],\n",
      "          [-1.5759e-01, -1.8017e-01, -1.8664e-01, -2.7230e-02, -3.5464e-02],\n",
      "          [-1.0127e-01, -4.6982e-02,  4.9144e-02,  2.0538e-02,  2.1793e-02]],\n",
      "\n",
      "         [[-1.3152e-02,  1.4736e-01,  1.0399e-01, -1.2080e-02,  4.0417e-02],\n",
      "          [-9.6379e-02,  2.5246e-02,  4.2741e-02,  5.9157e-02, -1.4824e-01],\n",
      "          [-2.8333e-01, -1.8666e-01,  1.4705e-01,  1.6862e-01,  6.9530e-02],\n",
      "          [-2.0921e-01, -2.8310e-01, -7.4247e-02,  1.7242e-01,  1.6510e-01],\n",
      "          [-6.8565e-02, -6.0282e-02, -2.2618e-01, -1.9767e-01,  7.3764e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1352e-02, -8.0236e-02, -1.3221e-01, -1.3521e-01, -6.8935e-02],\n",
      "          [ 6.3343e-02, -1.3074e-01, -2.3708e-01, -2.7047e-01, -1.5421e-01],\n",
      "          [ 1.4625e-01, -1.7887e-01, -2.6908e-01, -4.7937e-01, -3.1377e-01],\n",
      "          [-2.7610e-01, -3.7895e-01, -2.5170e-01, -1.1548e-01, -1.3455e-01],\n",
      "          [-3.7616e-01, -3.0869e-01, -9.8127e-02, -5.6358e-02, -7.8633e-02]],\n",
      "\n",
      "         [[-1.1496e-01, -1.8518e-02, -1.3319e-02,  3.2125e-02, -7.1838e-03],\n",
      "          [ 1.9242e-01,  8.1515e-02,  8.5765e-03, -9.4875e-02, -1.8704e-01],\n",
      "          [ 8.9014e-02,  1.6971e-01,  2.6163e-02, -1.5392e-01, -6.0736e-02],\n",
      "          [ 2.9157e-02,  1.2623e-01, -5.0877e-02,  4.7785e-02, -1.8980e-02],\n",
      "          [-1.4032e-01, -7.6451e-02, -3.0362e-02,  9.6664e-02, -4.6567e-02]],\n",
      "\n",
      "         [[ 1.8659e-01,  5.2051e-02,  1.3573e-01,  1.3741e-05,  3.9594e-02],\n",
      "          [ 3.0609e-01,  1.6113e-01, -1.5582e-01, -7.5089e-02,  2.0495e-01],\n",
      "          [ 2.9772e-01, -2.2687e-01, -9.6060e-02,  1.0513e-01,  1.6878e-01],\n",
      "          [-2.1073e-02, -1.5250e-01,  1.4785e-01,  1.3624e-01,  1.3978e-01],\n",
      "          [-1.3101e-01,  2.3168e-01,  1.5521e-01,  3.1483e-02, -1.9865e-02]],\n",
      "\n",
      "         [[ 1.0169e-01, -1.6032e-02, -6.6110e-02, -1.7133e-01,  8.5320e-02],\n",
      "          [ 9.9473e-02, -2.9043e-02, -1.9516e-01, -8.4457e-02,  9.2146e-02],\n",
      "          [-5.9811e-02, -1.1040e-01, -1.8512e-01,  3.0129e-02,  1.6411e-01],\n",
      "          [-5.6801e-02, -2.3265e-01,  6.0092e-02,  1.6420e-01,  1.4985e-01],\n",
      "          [-2.1649e-02,  1.0765e-01,  1.9525e-01,  1.5587e-01, -6.6950e-02]],\n",
      "\n",
      "         [[ 6.2447e-02, -1.0729e-01, -2.3878e-01, -3.4451e-01, -2.2287e-01],\n",
      "          [-4.8985e-02, -4.5506e-02, -3.5909e-01, -1.1034e-01, -5.5393e-03],\n",
      "          [ 4.0530e-02, -4.4309e-02, -8.2981e-02,  9.9847e-02,  1.1657e-01],\n",
      "          [-2.4083e-02, -2.8955e-01,  9.3937e-02,  1.4170e-01,  1.7665e-02],\n",
      "          [-5.5374e-02,  1.8075e-01,  2.4444e-01,  8.9531e-02,  5.7009e-02]],\n",
      "\n",
      "         [[ 1.6498e-02, -8.0809e-02, -2.6370e-01, -3.8113e-01, -1.9190e-01],\n",
      "          [ 8.4420e-02, -7.0448e-02, -1.0806e-01, -1.8708e-01, -6.8353e-03],\n",
      "          [-5.9061e-02, -2.3605e-01,  7.9373e-03, -5.8280e-04,  6.0048e-04],\n",
      "          [-1.4248e-01, -7.7000e-02,  2.7932e-02, -1.2154e-02, -8.8680e-02],\n",
      "          [-4.6244e-02,  7.7126e-02,  1.1683e-01, -1.0219e-02,  3.1148e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2529e-01,  1.1394e-01,  1.1139e-01,  1.1173e-01,  1.7152e-01],\n",
      "          [ 1.3787e-01,  8.3386e-02, -2.7017e-01, -1.1806e-01,  3.3061e-01],\n",
      "          [ 8.7508e-02,  6.8431e-02,  6.2285e-02, -3.3732e-01, -4.4240e-01],\n",
      "          [-3.4561e-02, -4.4235e-02,  3.6080e-02,  9.4501e-03, -7.2918e-02],\n",
      "          [ 8.1042e-03, -9.7846e-03, -7.5435e-02,  3.8588e-02,  1.2417e-01]],\n",
      "\n",
      "         [[-2.0470e-01, -1.9416e-01, -1.1199e-01, -6.4936e-02, -1.0454e-02],\n",
      "          [-2.9347e-01, -3.1692e-01, -4.1486e-01, -2.3169e-01,  3.2590e-02],\n",
      "          [-2.3685e-01, -3.3971e-01, -2.5457e-01, -3.1946e-02, -5.8768e-03],\n",
      "          [-2.7091e-01, -2.7067e-01, -1.4847e-01,  1.7429e-01,  3.7649e-03],\n",
      "          [-1.2324e-01, -2.7160e-01, -3.9937e-02,  1.0447e-01,  9.8240e-02]],\n",
      "\n",
      "         [[ 1.3062e-01,  4.3740e-03, -1.6588e-01,  1.5777e-01,  2.8298e-01],\n",
      "          [ 6.9575e-02,  4.8939e-02, -1.4254e-01,  9.0010e-02,  2.2153e-01],\n",
      "          [ 8.5300e-02, -9.6669e-02, -2.4703e-01, -7.1886e-02,  3.3699e-02],\n",
      "          [ 1.0289e-01, -6.9710e-02, -7.3268e-02, -1.4051e-01, -1.9770e-01],\n",
      "          [-4.2289e-03, -4.2198e-02, -9.8814e-02, -1.1383e-01, -8.2809e-02]],\n",
      "\n",
      "         [[ 6.8215e-02, -3.6927e-03, -1.4256e-01, -1.5249e-01, -1.6667e-01],\n",
      "          [-1.9279e-02, -4.2115e-02, -4.9177e-02, -1.1397e-01, -5.7879e-02],\n",
      "          [ 3.5247e-02,  1.3879e-02,  1.0385e-01,  2.5604e-02, -6.0861e-02],\n",
      "          [ 4.3667e-02,  1.0125e-01,  1.7160e-01,  1.0075e-01, -1.3858e-02],\n",
      "          [-3.7681e-03, -9.4137e-03,  1.2848e-01,  6.6535e-02, -3.0080e-02]],\n",
      "\n",
      "         [[-1.0047e-02, -1.6478e-02, -1.0670e-01, -2.2692e-03,  1.7075e-01],\n",
      "          [ 1.7232e-02, -1.8874e-02, -1.4900e-01, -1.9521e-01,  1.4339e-02],\n",
      "          [-1.0706e-01, -2.5497e-02,  1.1393e-01, -4.5869e-02, -1.8325e-01],\n",
      "          [-7.4529e-02, -1.0522e-01,  2.8551e-03,  4.4502e-02,  5.5053e-02],\n",
      "          [-4.1924e-03,  3.8758e-02,  4.0790e-02, -5.4582e-04,  1.1895e-01]],\n",
      "\n",
      "         [[-5.1196e-02,  1.0375e-01, -1.7430e-01, -6.6914e-02,  4.1839e-02],\n",
      "          [ 2.3553e-02,  1.4400e-01, -1.7640e-03, -1.0212e-01, -2.5468e-01],\n",
      "          [-8.6210e-02,  1.2121e-01,  1.4923e-01,  8.3653e-02,  4.6017e-02],\n",
      "          [-4.3472e-02,  2.5945e-02, -1.9641e-03,  5.0718e-02,  2.0359e-01],\n",
      "          [-1.1020e-01, -1.5085e-02, -1.7941e-02,  7.6341e-02,  8.1519e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.0408e-02, -2.3750e-01, -7.2105e-03, -1.9904e-01, -8.8839e-02],\n",
      "          [ 4.2325e-02, -1.2624e-01, -8.7520e-02, -7.7367e-02,  3.5781e-02],\n",
      "          [ 1.5424e-01,  7.1762e-02,  9.1668e-02,  8.1659e-02,  2.7079e-02],\n",
      "          [ 8.7084e-02,  1.0885e-01,  3.3790e-02, -9.0606e-03, -4.1502e-02],\n",
      "          [-1.4497e-01, -2.5203e-01, -1.7440e-01, -8.4333e-02, -1.5649e-01]],\n",
      "\n",
      "         [[-6.3620e-02,  5.9257e-02, -9.5997e-03,  1.3996e-01,  1.3093e-01],\n",
      "          [-3.5281e-02, -2.7254e-01, -2.5278e-01, -7.3684e-02, -1.0190e-01],\n",
      "          [ 3.8283e-02,  6.0827e-02,  5.2121e-02, -1.1867e-01, -1.2867e-01],\n",
      "          [-5.4297e-02,  1.7794e-01,  1.1991e-01,  5.0157e-03, -1.1056e-01],\n",
      "          [-3.2104e-02, -8.7581e-02, -1.2184e-01, -1.1638e-01, -3.7628e-02]],\n",
      "\n",
      "         [[ 2.4138e-01,  1.9773e-02,  2.2167e-01,  2.5529e-02, -1.7278e-01],\n",
      "          [-8.9616e-02,  9.7894e-04,  8.7557e-02, -1.6268e-01, -7.0245e-02],\n",
      "          [ 4.9401e-02, -2.5127e-02, -1.7171e-01, -2.7617e-01, -2.2131e-01],\n",
      "          [ 5.0324e-02, -1.0515e-01, -1.1917e-01, -1.0922e-01, -2.0760e-01],\n",
      "          [-1.1422e-01, -4.9971e-02, -5.2089e-02, -8.3417e-02, -4.3964e-02]],\n",
      "\n",
      "         [[ 1.1922e-01, -1.3499e-01,  1.0521e-01,  7.9679e-02, -1.1940e-01],\n",
      "          [ 3.4127e-02,  1.3175e-01,  6.6127e-02, -6.0988e-02,  1.6154e-01],\n",
      "          [-1.1044e-01,  7.1418e-02, -2.4383e-03,  3.0397e-02,  1.8736e-01],\n",
      "          [-1.2310e-01, -1.2047e-01, -4.2162e-02,  1.3251e-01,  1.2930e-01],\n",
      "          [-4.0229e-02,  1.0096e-01,  8.5426e-02,  1.0609e-01,  1.1500e-01]],\n",
      "\n",
      "         [[ 7.7210e-03, -2.3449e-02,  1.7217e-01,  1.0129e-01, -1.5124e-01],\n",
      "          [-7.5073e-02, -3.3819e-02,  6.3157e-02,  1.8008e-02,  1.3637e-01],\n",
      "          [ 1.6088e-01,  1.3828e-01,  4.4908e-02,  8.2045e-02,  1.1060e-01],\n",
      "          [-1.1252e-01,  2.0865e-02,  4.0690e-02, -1.0989e-01, -6.2514e-02],\n",
      "          [-3.9136e-02, -7.3254e-03,  7.9162e-02, -1.0519e-01, -1.3854e-01]],\n",
      "\n",
      "         [[-1.1062e-01, -1.7291e-01, -1.9724e-01,  4.2192e-02,  3.0557e-02],\n",
      "          [ 5.7983e-02,  6.6355e-02,  1.4812e-02,  1.2155e-01,  1.1560e-01],\n",
      "          [ 1.0117e-01,  7.8965e-02,  1.0807e-01,  3.4782e-02,  4.2559e-02],\n",
      "          [-6.1940e-02, -2.0615e-01,  2.3694e-02, -1.0100e-01,  5.7334e-02],\n",
      "          [ 9.5344e-02, -1.0741e-01, -6.4576e-02, -5.6568e-03, -6.1190e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9047e-02,  8.0034e-02,  1.2853e-01,  1.6979e-01,  1.2950e-01],\n",
      "          [ 1.0779e-03,  8.8662e-02,  1.9992e-01,  3.1613e-02, -3.3004e-02],\n",
      "          [-2.1137e-01, -1.5315e-01, -3.9836e-01, -2.6205e-01, -2.0643e-01],\n",
      "          [-1.5485e-01, -1.0825e-01, -2.4380e-01,  5.1562e-02,  1.3896e-01],\n",
      "          [ 3.4707e-02,  6.5452e-02, -2.6441e-02,  3.4789e-02,  1.4373e-01]],\n",
      "\n",
      "         [[-6.6336e-02, -1.4828e-01, -1.1606e-01,  7.5257e-02,  1.4329e-01],\n",
      "          [ 2.7349e-02,  1.4907e-01,  2.0500e-01,  1.5177e-01, -6.7520e-02],\n",
      "          [ 3.7377e-02,  9.1939e-02,  3.4783e-02, -2.2715e-01, -4.6271e-02],\n",
      "          [-9.8406e-02, -2.3612e-01, -1.1668e-01,  4.5252e-02,  4.6814e-02],\n",
      "          [-1.8336e-01, -5.1079e-02, -4.1495e-02, -3.7102e-02, -3.5919e-02]],\n",
      "\n",
      "         [[-6.3615e-02,  1.4635e-01,  2.0224e-01,  8.8135e-03, -2.3806e-01],\n",
      "          [-1.3421e-01, -1.1099e-01, -2.5253e-01, -1.6049e-01, -5.0420e-02],\n",
      "          [-2.1683e-01, -2.9399e-01, -1.1538e-01,  6.7897e-02,  9.5384e-02],\n",
      "          [ 8.5892e-02,  7.5724e-02,  2.9613e-02,  6.9357e-02, -3.7451e-02],\n",
      "          [ 1.9399e-01,  1.6367e-01,  8.1093e-02, -1.2663e-01, -2.0992e-01]],\n",
      "\n",
      "         [[-3.4967e-01, -2.0753e-01, -6.4900e-02,  1.3567e-02, -1.7313e-01],\n",
      "          [-4.4426e-01, -1.6541e-01, -2.2337e-01, -1.2988e-01,  7.3810e-02],\n",
      "          [-3.2792e-01, -1.4567e-01,  2.5690e-02,  1.2843e-01,  1.0429e-01],\n",
      "          [ 5.2679e-02,  1.8683e-01,  1.3343e-01,  1.6850e-01,  4.2553e-02],\n",
      "          [ 1.4773e-02,  6.3696e-02,  3.8574e-02, -7.5423e-03, -1.1719e-01]],\n",
      "\n",
      "         [[-2.8809e-01, -1.5033e-01,  3.4114e-03, -5.1282e-02, -2.3500e-02],\n",
      "          [-2.8136e-01, -6.4324e-02, -4.3154e-02, -2.5300e-01,  3.4933e-02],\n",
      "          [-3.8312e-01, -1.9570e-01,  6.5850e-02,  1.9126e-01,  1.6677e-01],\n",
      "          [ 2.6572e-02,  1.1721e-01,  1.1854e-01,  1.3549e-01,  1.5950e-02],\n",
      "          [ 1.2031e-01,  1.4710e-01, -2.9582e-02, -8.5421e-02, -1.7351e-01]],\n",
      "\n",
      "         [[-1.9269e-01, -4.7337e-02,  3.8853e-03,  2.0357e-03, -6.8562e-02],\n",
      "          [-4.0677e-01, -1.6577e-01, -9.4426e-02, -2.0959e-03,  6.4701e-02],\n",
      "          [-1.5166e-02,  4.4216e-02,  7.0968e-02,  2.1351e-02,  7.1843e-02],\n",
      "          [ 7.9172e-02,  1.7108e-01,  6.5137e-02, -8.3516e-02, -5.4001e-02],\n",
      "          [ 6.2355e-02, -1.0176e-01, -8.5676e-02,  1.5303e-02, -9.8490e-02]]]],\n",
      "       requires_grad=True)), ('conv2.bias', Parameter containing:\n",
      "tensor([-0.0357, -0.0601,  0.0708, -0.0546,  0.0626, -0.1397,  0.0607, -0.0693,\n",
      "        -0.0620, -0.0220, -0.0079, -0.0528, -0.1056,  0.0234,  0.0506, -0.1384],\n",
      "       requires_grad=True)), ('fc1.weight', Parameter containing:\n",
      "tensor([[ 4.1703e-02, -4.1024e-02, -5.7866e-02,  ...,  3.1474e-02,\n",
      "         -7.1902e-02, -1.5127e-01],\n",
      "        [-6.5600e-02, -8.8797e-02,  1.2986e-04,  ..., -7.2424e-02,\n",
      "         -5.6693e-02,  5.4791e-02],\n",
      "        [-8.3491e-02,  3.9688e-02,  4.9615e-02,  ..., -2.4020e-02,\n",
      "          3.7125e-02,  1.8223e-01],\n",
      "        ...,\n",
      "        [-1.1876e-02, -4.7364e-02,  2.0696e-02,  ...,  2.8118e-02,\n",
      "          3.1017e-03, -2.1101e-02],\n",
      "        [-2.0437e-02, -8.2487e-02, -2.9455e-02,  ...,  8.6710e-02,\n",
      "         -1.5751e-02,  6.7023e-03],\n",
      "        [-2.5032e-02, -3.9433e-02, -9.2791e-04,  ..., -5.3595e-02,\n",
      "         -3.6494e-03, -4.3658e-02]], requires_grad=True)), ('fc1.bias', Parameter containing:\n",
      "tensor([ 0.0305, -0.0451,  0.0749, -0.0321,  0.0374,  0.0310,  0.0353,  0.0235,\n",
      "         0.0511, -0.0430,  0.0073, -0.0311, -0.0279,  0.1253, -0.0522,  0.0597,\n",
      "        -0.0654, -0.0097, -0.0205, -0.0154,  0.0284, -0.0293, -0.0036, -0.0131,\n",
      "        -0.0229, -0.0853, -0.0153, -0.0628,  0.0142,  0.0615, -0.0341, -0.0421,\n",
      "         0.0408, -0.0627,  0.0715, -0.0098, -0.0208, -0.0023,  0.0436, -0.0622,\n",
      "        -0.0567, -0.0543, -0.0208, -0.0604, -0.0342,  0.0171,  0.0497, -0.0144,\n",
      "         0.0263, -0.0236,  0.0914, -0.0144,  0.0242, -0.0186, -0.1244, -0.0236,\n",
      "         0.0215, -0.0591,  0.1348, -0.0405,  0.0312, -0.0094, -0.0454, -0.0018,\n",
      "         0.0423,  0.0568,  0.0677,  0.0488,  0.0081, -0.0464,  0.0301,  0.0006,\n",
      "        -0.0138, -0.0578, -0.0061, -0.0265, -0.0155,  0.0446, -0.0045, -0.0200,\n",
      "         0.0139, -0.0434,  0.0127, -0.0054,  0.0462,  0.0322, -0.0019, -0.0298,\n",
      "         0.0364,  0.0356, -0.0547,  0.0600,  0.0051, -0.0189, -0.0421,  0.0323,\n",
      "         0.0106, -0.0296, -0.0147,  0.0558,  0.0275, -0.0068, -0.0160,  0.0339,\n",
      "         0.0628, -0.0539, -0.0249, -0.0400, -0.0643, -0.0366, -0.0536,  0.0013,\n",
      "        -0.0423, -0.0116,  0.0030, -0.1015,  0.0044,  0.0335, -0.0743,  0.0126],\n",
      "       requires_grad=True)), ('fc2.weight', Parameter containing:\n",
      "tensor([[-0.1300,  0.0365,  0.0300,  ..., -0.0665,  0.0700,  0.0600],\n",
      "        [-0.2038,  0.0199,  0.0087,  ..., -0.0847, -0.0591,  0.0567],\n",
      "        [-0.0105,  0.0175,  0.0052,  ...,  0.0181,  0.0643, -0.0867],\n",
      "        ...,\n",
      "        [ 0.0554,  0.1323, -0.2041,  ..., -0.1135, -0.1884, -0.0712],\n",
      "        [-0.1269,  0.0548,  0.0872,  ...,  0.0082, -0.0064,  0.0321],\n",
      "        [ 0.0634,  0.0102,  0.0311,  ..., -0.0980,  0.1049,  0.0597]],\n",
      "       requires_grad=True)), ('fc2.bias', Parameter containing:\n",
      "tensor([ 2.3624e-02, -1.0001e-02, -8.6486e-02, -5.6539e-02,  4.7810e-02,\n",
      "        -6.9790e-03, -9.1544e-02, -2.0982e-02,  1.7927e-01, -3.5965e-02,\n",
      "         1.5334e-02,  5.0402e-02,  4.3169e-02, -1.1582e-01, -1.0194e-01,\n",
      "        -7.8611e-02, -1.1707e-01, -5.6527e-02,  5.5769e-02,  1.2905e-01,\n",
      "         3.6091e-02,  5.3192e-02,  2.9158e-02, -1.4346e-01, -8.5933e-02,\n",
      "         5.9107e-02,  4.3795e-02,  2.6747e-02, -9.3827e-02, -4.0142e-02,\n",
      "         5.9818e-02,  2.7496e-02,  5.0302e-02, -8.7522e-03,  6.7265e-02,\n",
      "         2.6070e-02,  4.5610e-02,  7.1293e-02,  5.6788e-02,  2.1033e-01,\n",
      "        -3.6036e-03, -1.2985e-01, -1.8190e-02, -9.5545e-02,  1.3988e-02,\n",
      "        -2.7872e-02, -1.1023e-01,  2.6600e-02,  6.6529e-02, -4.2607e-02,\n",
      "        -2.9298e-02, -5.8356e-02, -1.7782e-02,  3.2561e-02,  1.3698e-02,\n",
      "        -1.2275e-01,  2.1490e-02, -6.7376e-02, -5.6269e-02,  9.9335e-02,\n",
      "         1.5163e-02,  1.8656e-02,  2.2705e-02, -1.0080e-01,  5.4350e-02,\n",
      "        -5.5680e-02,  1.3402e-02,  1.1261e-04, -4.2462e-02,  1.2215e-01,\n",
      "         8.3890e-02, -1.2703e-01, -8.9533e-02, -7.2130e-02,  3.0785e-02,\n",
      "         6.2039e-02, -1.6366e-01, -8.7658e-02,  5.2735e-02, -1.1121e-02,\n",
      "         1.6129e-01, -7.1250e-02,  2.1835e-02,  9.8091e-02],\n",
      "       requires_grad=True)), ('fc3.weight', Parameter containing:\n",
      "tensor([[ 1.2223e-01, -1.0053e-01, -2.4008e-01, -8.6781e-02, -2.5556e-01,\n",
      "         -7.8704e-02, -1.6585e-01, -1.2797e-01, -1.8740e-01,  1.4493e-01,\n",
      "         -2.4143e-01, -2.2979e-01, -3.6082e-02, -3.3965e-02,  5.4032e-03,\n",
      "          6.3030e-02, -4.4754e-02, -1.6966e-01,  2.4908e-02, -1.9261e-01,\n",
      "          3.9072e-02, -1.1838e-01, -1.3133e-02, -9.6312e-02, -1.4400e-01,\n",
      "         -1.6905e-01,  1.4976e-02, -1.1391e-01, -1.3283e-01,  1.6791e-02,\n",
      "         -2.5712e-02, -1.3855e-01, -1.8744e-01,  1.6521e-01,  1.8413e-01,\n",
      "         -3.0824e-02,  9.3730e-02,  8.2055e-02, -1.6973e-01,  1.1878e-01,\n",
      "         -1.2673e-02, -1.0495e-01,  5.1364e-02, -6.0383e-02, -3.0656e-01,\n",
      "         -6.9766e-01, -8.3890e-02, -1.1561e-01, -7.3265e-02,  9.6652e-02,\n",
      "          1.4830e-01,  2.0703e-02, -6.2746e-02,  1.7441e-01,  3.9373e-02,\n",
      "          1.9341e-02, -4.1998e-02, -4.0335e-02,  2.3257e-02,  1.1414e-01,\n",
      "         -1.6738e-01, -1.0063e-01,  7.3073e-02, -2.5888e-02,  9.4152e-02,\n",
      "          1.0421e-01, -1.0148e-01, -1.8153e-01, -1.2209e-01,  2.2543e-02,\n",
      "          6.7293e-02, -4.4673e-02, -7.4939e-02, -1.3702e-01,  6.0404e-02,\n",
      "         -2.1399e-01, -7.6831e-02, -4.1614e-02,  7.5324e-02,  2.3032e-02,\n",
      "         -1.1882e-01, -1.8290e-01,  1.5185e-01, -1.8882e-01],\n",
      "        [ 8.9410e-02, -7.4615e-02, -1.4876e-01, -8.8151e-02, -7.1323e-02,\n",
      "         -1.4024e-01, -2.5138e-02,  4.2136e-03,  3.0140e-02, -8.3495e-02,\n",
      "          1.0196e-01,  7.6576e-02, -2.2181e-01, -7.1835e-04, -1.5260e-01,\n",
      "         -9.3140e-02, -6.1718e-02, -1.0180e-01, -2.3676e-01, -3.3981e-03,\n",
      "         -1.1836e-01, -3.1271e-02, -1.0258e-01, -3.5595e-02,  2.4858e-02,\n",
      "          1.4981e-01, -2.8958e-01,  8.3846e-02,  3.9425e-02,  1.1648e-01,\n",
      "         -2.7576e-01,  1.8681e-01, -6.9600e-02, -3.0976e-02,  6.1881e-02,\n",
      "         -4.1029e-02, -1.6856e-01, -1.6690e-01,  2.0023e-01, -8.6573e-02,\n",
      "          1.2081e-01, -1.6412e-01,  3.7206e-02, -1.4215e-01,  1.1582e-01,\n",
      "          2.9675e-01, -1.4025e-01,  1.3647e-01, -1.6935e-01,  2.8149e-02,\n",
      "         -3.1853e-01,  5.6713e-02,  6.7658e-02,  1.9667e-01,  8.5432e-02,\n",
      "         -9.4586e-02, -8.1562e-02, -5.0831e-03, -1.2502e-01, -8.5013e-02,\n",
      "         -8.8211e-02,  1.0391e-01,  1.5510e-02, -1.1517e-01, -1.7445e-02,\n",
      "         -2.4866e-01, -4.0850e-02,  6.2959e-02, -2.9952e-02, -1.6774e-01,\n",
      "         -1.2247e-01,  3.0892e-02,  3.9418e-02, -2.5770e-01,  1.3141e-01,\n",
      "          1.1999e-01, -4.6814e-01, -2.0112e-01,  1.0497e-01, -3.3113e-02,\n",
      "          4.9643e-02, -5.3289e-02, -8.5387e-02,  4.8173e-02],\n",
      "        [-1.1024e-01,  1.5592e-02,  2.0613e-02, -7.7696e-02, -1.9010e-01,\n",
      "          8.2902e-02,  1.1364e-01, -1.2927e-01, -1.8940e-01,  5.7853e-02,\n",
      "         -6.4902e-02,  1.1524e-01, -2.4439e-01, -4.3460e-02, -1.6632e-01,\n",
      "          1.1222e-01,  9.6094e-02,  1.9265e-02, -1.2532e-01, -2.1742e-01,\n",
      "          3.2926e-02,  1.0698e-01,  5.1289e-02, -2.1363e-01, -1.1743e-02,\n",
      "         -1.0805e-02,  1.6609e-02,  1.8645e-01,  8.7136e-02,  6.2241e-02,\n",
      "          1.4440e-02,  8.6236e-02, -1.7855e-01, -1.6273e-01, -2.5203e-01,\n",
      "         -4.1432e-02, -1.1523e-01, -5.8437e-02, -1.4942e-01, -8.3839e-02,\n",
      "          1.0038e-01,  3.9830e-02,  1.0025e-01,  1.3631e-01, -1.1897e-01,\n",
      "         -1.9417e-01, -1.0310e-01, -7.2120e-03, -1.7116e-01, -1.5381e-01,\n",
      "         -1.7671e-01,  8.7476e-02,  3.4322e-02, -1.9622e-01, -1.8785e-01,\n",
      "         -1.0354e-01, -5.5864e-02,  2.8731e-02,  8.4113e-02, -7.7838e-02,\n",
      "          1.0217e-01, -1.6842e-01,  1.5563e-01,  1.4142e-01, -1.8982e-01,\n",
      "          2.0652e-02,  1.1711e-02, -1.9485e-01,  9.1802e-02,  3.8353e-02,\n",
      "         -3.7610e-02, -1.2884e-01, -1.1070e-01,  3.2550e-02, -4.8420e-02,\n",
      "          8.8997e-02, -3.0920e-02, -1.1658e-01,  5.3510e-02, -1.1765e-01,\n",
      "          7.4015e-02, -2.7199e-01,  6.0939e-03, -1.6041e-01],\n",
      "        [-1.7692e-01,  1.1096e-02, -1.3667e-01,  1.0412e-01, -3.4436e-02,\n",
      "         -2.4674e-02,  4.2214e-02,  1.9031e-02,  1.7101e-02, -9.8179e-02,\n",
      "          3.3473e-02,  2.5367e-02, -9.1588e-02, -4.4599e-02, -2.4986e-01,\n",
      "         -1.4667e-01, -1.9143e-01,  7.5651e-02,  2.9837e-02,  7.9499e-02,\n",
      "          1.4783e-01, -2.6584e-02, -2.4156e-01, -4.6906e-02,  1.4944e-02,\n",
      "         -3.4819e-01,  7.0527e-02,  3.2168e-02, -6.3647e-02, -1.8909e-01,\n",
      "          5.7332e-02, -3.6270e-01, -1.2855e-01, -1.7510e-01,  9.5834e-03,\n",
      "          3.0909e-02, -1.4592e-01,  7.6518e-02, -2.4335e-01,  1.2238e-01,\n",
      "         -1.2737e-01, -2.4721e-02,  1.1661e-01, -1.2390e-02, -1.6878e-02,\n",
      "         -6.0939e-02, -2.3362e-02,  8.0170e-02, -1.6516e-01, -7.6296e-02,\n",
      "         -7.5877e-02, -1.6613e-02, -9.7964e-02, -7.0443e-02,  7.5273e-02,\n",
      "         -8.5921e-02,  5.9501e-02, -7.6320e-02, -9.5040e-02,  1.7116e-01,\n",
      "          6.7204e-02,  4.2406e-02, -8.0410e-02, -1.2192e-01, -1.2704e-01,\n",
      "          1.6082e-01, -1.3813e-01,  1.3300e-01,  9.1880e-03,  3.6654e-02,\n",
      "          7.6924e-02, -1.1322e-02,  2.6665e-02, -2.0524e-02,  1.3895e-01,\n",
      "          2.4607e-02, -1.1161e-01, -2.2939e-01,  1.3110e-01, -1.1005e-01,\n",
      "          1.7996e-01,  7.4799e-02, -1.7801e-01, -1.9943e-01],\n",
      "        [-2.4708e-01,  9.8579e-02, -9.8773e-02, -7.7524e-02,  1.0977e-01,\n",
      "         -1.4826e-01,  3.7045e-02, -1.2978e-01,  6.0347e-02, -1.6361e-01,\n",
      "         -1.3247e-01, -1.4812e-01, -4.8455e-02,  2.4347e-02,  4.5220e-03,\n",
      "          2.0700e-01, -1.1445e-01,  1.0232e-01,  3.7935e-02, -1.1472e-02,\n",
      "         -1.2147e-01,  5.4933e-02, -9.5326e-02, -9.7458e-02,  6.1093e-02,\n",
      "          9.4748e-02,  7.3536e-02,  5.7004e-02, -1.3294e-01,  8.5931e-02,\n",
      "          1.0121e-01, -2.2483e-02,  1.4757e-01,  3.5889e-02,  6.4400e-02,\n",
      "         -2.1421e-01, -1.0850e-01, -3.5618e-02,  9.1378e-02, -2.5793e-01,\n",
      "          1.0662e-01,  2.7725e-02, -1.4569e-01, -1.0594e-02,  1.5374e-01,\n",
      "          1.7107e-03, -6.0336e-02,  8.4592e-02, -1.7684e-01, -1.4860e-01,\n",
      "         -1.3002e-01, -8.1741e-02,  8.2384e-02, -9.6780e-02, -1.1968e-01,\n",
      "          1.1512e-01, -3.8334e-02, -1.3551e-01,  6.0607e-02, -2.5643e-01,\n",
      "         -2.6421e-01, -2.3376e-02, -2.0718e-01,  8.8634e-02, -1.2262e-01,\n",
      "         -1.5626e-01,  1.6609e-01, -2.1716e-02,  1.1350e-01, -1.4243e-01,\n",
      "          1.1653e-02, -2.4085e-03, -6.6217e-02,  9.9333e-02,  8.7429e-02,\n",
      "         -1.4254e-01, -1.0849e-01,  1.3777e-01, -1.9662e-01, -2.0859e-01,\n",
      "         -1.5106e-01,  1.3382e-01,  1.6667e-01,  1.2694e-01],\n",
      "        [ 1.4239e-01,  9.1498e-02, -1.3939e-01,  3.4096e-03,  1.0428e-01,\n",
      "         -1.5543e-01,  5.5258e-02,  2.7454e-02,  6.9090e-02, -1.9484e-02,\n",
      "         -3.4350e-02,  1.2488e-01,  4.3794e-02,  1.5577e-02,  4.3561e-02,\n",
      "          8.9077e-03, -2.2803e-01, -5.0128e-03,  7.1403e-02,  8.0181e-02,\n",
      "         -1.1000e-01, -1.2707e-01,  7.0828e-02, -1.5055e-01, -1.5350e-01,\n",
      "         -1.9144e-02, -2.3940e-03,  9.5582e-03, -1.3803e-01, -7.2630e-02,\n",
      "          1.2472e-01, -1.3804e-01, -3.1894e-01, -1.0810e-01, -2.5412e-01,\n",
      "          1.2922e-01, -5.1156e-02,  1.6092e-01, -2.4998e-01,  9.2451e-02,\n",
      "         -1.7929e-01,  4.0078e-02, -1.7474e-01,  5.3316e-02, -7.0901e-02,\n",
      "         -2.2993e-01,  2.0252e-01,  4.6896e-03, -9.2224e-02,  1.9384e-01,\n",
      "          2.7805e-02,  6.9356e-02,  8.4357e-02, -8.0685e-03,  1.3380e-01,\n",
      "         -1.6752e-01, -2.0367e-02,  8.9862e-03, -5.5522e-02,  7.2815e-02,\n",
      "         -1.5044e-02,  7.7815e-02, -5.6798e-02,  7.0471e-02, -4.7291e-02,\n",
      "         -6.3457e-02, -2.3274e-02,  8.3285e-02, -1.6470e-01, -1.4330e-01,\n",
      "          6.4477e-02, -4.4593e-02,  6.5541e-02, -4.8679e-02, -9.6300e-02,\n",
      "          1.0516e-01, -1.3889e-01, -2.7305e-02, -2.2175e-02,  1.6836e-03,\n",
      "         -2.4675e-02, -1.0352e-01, -1.2839e-01,  6.1860e-02],\n",
      "        [-3.1326e-02,  3.6895e-03, -3.4783e-01, -1.3404e-01, -4.6472e-02,\n",
      "         -9.3308e-02,  6.2389e-02, -3.3241e-02,  7.5124e-02,  2.6978e-02,\n",
      "         -9.0789e-02, -1.4867e-02,  9.2730e-02, -8.6380e-02,  9.6752e-02,\n",
      "         -3.7679e-02, -6.8861e-01, -1.1680e-01, -1.3940e-01, -2.9829e-01,\n",
      "         -2.3306e-01, -2.8842e-01,  1.4617e-01,  5.9938e-02,  2.6082e-02,\n",
      "          4.5599e-02,  1.3673e-01, -9.2060e-02, -9.7761e-04,  1.2281e-01,\n",
      "         -2.2995e-01, -1.1751e-01, -3.3818e-02, -2.8004e-02,  1.2144e-01,\n",
      "         -1.5944e-01,  1.3834e-01,  7.5956e-02, -1.7381e-01,  3.1876e-03,\n",
      "         -3.8291e-02,  5.6749e-02, -1.9103e-01, -2.5111e-01, -7.6404e-02,\n",
      "         -1.6673e-01,  2.8579e-02, -1.9944e-02,  1.6144e-02,  5.9893e-02,\n",
      "          1.7383e-01,  6.1433e-03, -1.4805e-01,  9.6958e-02, -1.7333e-01,\n",
      "         -7.0147e-02,  2.4518e-02, -1.3234e-01, -2.7110e-01,  8.1252e-02,\n",
      "          1.4442e-01,  9.7579e-02, -7.6343e-02, -9.5472e-02,  1.2497e-01,\n",
      "         -3.9746e-02, -6.4830e-02, -1.5443e-01, -2.2444e-01, -5.5909e-02,\n",
      "         -3.3824e-01, -3.3544e-02, -6.6514e-03,  8.8904e-02, -2.8684e-02,\n",
      "          1.1718e-01,  6.3523e-02,  9.8914e-02, -1.1571e-01, -1.3489e-01,\n",
      "         -3.7010e-02, -1.7218e-01,  3.6440e-02, -1.4868e-03],\n",
      "        [ 7.9886e-02, -1.4534e-01, -7.2389e-02,  8.4066e-02,  3.6520e-02,\n",
      "         -1.7794e-01, -3.6319e-02, -8.9381e-02, -2.0576e-01, -3.1072e-01,\n",
      "         -7.4886e-02,  3.7272e-02, -3.2528e-02, -2.2911e-02,  2.0549e-01,\n",
      "         -2.3410e-01,  4.4020e-02,  1.0893e-02, -2.4744e-01,  1.8171e-02,\n",
      "         -1.0665e-01,  1.3772e-01, -1.3469e-01, -3.2079e-02,  1.0258e-01,\n",
      "         -9.1644e-03, -6.8289e-02,  5.5561e-02,  1.7324e-01, -1.7767e-02,\n",
      "         -7.8359e-02, -5.3412e-03,  1.4875e-01,  6.4486e-03, -8.0500e-02,\n",
      "         -9.4366e-02,  7.2092e-02,  9.5764e-02, -2.1398e-02, -2.7357e-03,\n",
      "         -2.5205e-01, -1.3536e-01,  1.8992e-01,  1.1607e-01,  1.0842e-01,\n",
      "         -9.0282e-02,  1.2388e-01,  2.0780e-01, -3.3696e-02, -1.1711e-01,\n",
      "         -1.2791e-01, -1.2099e-02, -2.4278e-01, -1.1284e-01, -1.9814e-02,\n",
      "          9.7866e-02, -8.7115e-02, -9.0073e-02,  1.1046e-01, -1.3520e-01,\n",
      "         -2.3099e-02, -2.1933e-02, -1.0535e-01,  3.2021e-02, -2.7138e-01,\n",
      "         -2.3737e-01, -2.1736e-01,  6.1273e-04,  2.6023e-02, -1.7644e-01,\n",
      "          2.1063e-02, -1.0159e-01,  2.9213e-02, -8.1810e-02,  4.7275e-02,\n",
      "          9.5355e-03, -1.3170e-02, -1.0561e-01,  7.6708e-02, -9.9157e-02,\n",
      "          5.6368e-02,  7.2140e-02, -4.6227e-02,  2.6659e-02],\n",
      "        [ 7.5517e-02, -2.2356e-01,  3.8700e-02, -1.5007e-01,  1.1937e-01,\n",
      "          6.9733e-02, -9.8057e-02, -1.3643e-01,  1.6660e-01, -2.8692e-03,\n",
      "          1.0151e-01, -5.6951e-02,  9.2415e-03,  1.6354e-02, -3.4601e-02,\n",
      "         -8.4728e-02, -1.4574e-02, -2.2125e-01,  1.1568e-01,  9.6354e-02,\n",
      "          1.4598e-01,  7.8868e-02, -1.9144e-01, -9.3008e-02, -2.2200e-03,\n",
      "          1.1372e-01, -1.6122e-01, -3.3662e-01, -2.1431e-01,  8.1622e-02,\n",
      "         -2.5372e-01, -1.5897e-01, -1.6247e-02,  4.7507e-05, -2.3996e-01,\n",
      "         -3.1557e-02,  1.3378e-01, -9.5402e-02, -1.3023e-01,  1.1880e-01,\n",
      "         -1.0337e-01, -9.4998e-02,  1.6636e-02,  3.8809e-02, -1.8414e-01,\n",
      "         -1.5230e-01, -5.8968e-02, -2.4734e-01, -8.3196e-02, -1.5674e-01,\n",
      "         -2.1327e-01, -3.5226e-02,  1.5409e-01, -8.3482e-02, -1.1020e-01,\n",
      "         -2.1322e-01, -9.5520e-02, -1.9059e-02,  2.0643e-03, -1.3117e-02,\n",
      "          1.5177e-01, -1.1615e-01,  3.9835e-02, -6.7219e-02,  8.5023e-02,\n",
      "         -1.7330e-02,  1.1141e-01, -1.0286e-01,  8.3971e-02,  6.3797e-02,\n",
      "         -1.0623e-01,  5.3154e-02, -1.0342e-01,  2.3993e-02, -1.7772e-01,\n",
      "         -1.4576e-01, -5.4894e-02,  2.2578e-02, -1.7479e-01, -1.8795e-01,\n",
      "          1.0229e-01, -2.6785e-02, -2.4655e-01,  4.0356e-02],\n",
      "        [ 7.6440e-02, -2.9343e-02, -2.1976e-01,  9.8635e-02,  4.0145e-02,\n",
      "         -7.6753e-02, -3.5536e-01, -9.8553e-02,  1.0956e-01, -1.6776e-01,\n",
      "         -5.0428e-02,  4.3767e-02,  5.6481e-02, -7.9688e-02,  3.1919e-02,\n",
      "          6.0203e-02, -1.2038e-01,  9.9906e-02, -5.5153e-02,  7.7116e-03,\n",
      "          1.3081e-01,  1.0766e-01, -9.9205e-02, -1.0188e-01,  9.2846e-03,\n",
      "         -9.1564e-02, -1.8926e-02, -4.7298e-03, -7.1950e-02, -1.3304e-01,\n",
      "          1.8723e-01,  7.3776e-02,  1.2011e-01, -1.1212e-01,  1.2144e-01,\n",
      "          2.8035e-02, -5.6121e-02, -7.3255e-02,  1.5499e-01, -1.4853e-01,\n",
      "         -1.2697e-01,  5.5374e-03,  8.2072e-03,  7.8540e-03,  5.3306e-02,\n",
      "          1.2976e-01,  5.1551e-02, -4.9539e-02, -1.8461e-01, -1.5438e-01,\n",
      "         -2.5770e-01, -1.0841e-01, -1.4015e-01, -9.2201e-02,  1.8769e-01,\n",
      "          7.8177e-02, -6.3225e-02, -8.9514e-02,  6.8459e-02, -2.5756e-01,\n",
      "         -2.2166e-01, -2.1445e-01, -1.9150e-01,  2.7692e-02, -1.8074e-02,\n",
      "         -6.6647e-02,  1.1939e-01,  2.2019e-02, -7.5331e-02,  1.0695e-01,\n",
      "          1.2250e-01,  8.4335e-04, -6.4643e-02,  5.8724e-02,  1.1661e-01,\n",
      "         -2.1026e-01, -2.1150e-01, -6.8983e-02, -2.2926e-01, -1.7395e-01,\n",
      "         -3.0970e-01,  8.6698e-02,  1.5213e-01,  1.2065e-02]],\n",
      "       requires_grad=True)), ('fc3.bias', Parameter containing:\n",
      "tensor([ 0.0869, -0.1079, -0.1268, -0.0434,  0.0253, -0.0183, -0.0039,  0.0627,\n",
      "         0.0868,  0.0035], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'lenet_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip the training if already done and restart from here by loading existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('lenet_model.pth', weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unwrap model functions for quantization\n",
    "=======================================\n",
    "\n",
    "Here we will unwrap most of the functions for quantization and make it hardware friendly. The trained weights and biases from previous model is used inside the functions and the training phase is not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absmax_quantize(X:np.matrix) -> np.matrix:\n",
    "    # Calculate scale\n",
    "    scale = 127 / np.max(np.absolute(X))\n",
    "\n",
    "    # Quantize\n",
    "    X_quant = np.round(scale * X)\n",
    "\n",
    "    return X_quant.astype(np.int16), scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs256_quantize(X:np.matrix) -> np.matrix:\n",
    "    # Fix scale\n",
    "    scale = 256\n",
    "\n",
    "    # Quantize\n",
    "    X_quant = np.round(scale * X)\n",
    "\n",
    "    return X_quant.astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs256_dequantize(X:np.matrix) -> np.matrix:\n",
    "    # Fix scale\n",
    "    scale = 256\n",
    "\n",
    "    # Quantize\n",
    "    X_quant = np.round(X/scale)\n",
    "\n",
    "    return X_quant.astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38244924"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.detach(model.fc3.weight).numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  14,   12,    2,   54,  -47],\n",
       "         [ -21,   71,  142,  104,   33],\n",
       "         [ -39,  -42,   60,  113,   43],\n",
       "         [ -76,  -99,  -89,   26,   26],\n",
       "         [ -97, -100,  -62,  -56,   11]]],\n",
       "\n",
       "\n",
       "       [[[  87,   54,   77,   20,   37],\n",
       "         [  37,   95,   67,   41,   -1],\n",
       "         [  69,   35,   -6,    5,  -59],\n",
       "         [ -69,  -65, -111,  -36,  -46],\n",
       "         [-147, -141,  -63,  -18,   50]]],\n",
       "\n",
       "\n",
       "       [[[ -13,  -87,   -5,   16,   81],\n",
       "         [ -94,  -42,  -35,   35,   88],\n",
       "         [ -51,  -72,   75,   70,   24],\n",
       "         [ -77,    0,   52,  107,  -24],\n",
       "         [  -3,  -38,   47,   38,  -50]]],\n",
       "\n",
       "\n",
       "       [[[  59,  -15,   -8,   54,   35],\n",
       "         [ -33,  -39,   10,   37,    3],\n",
       "         [ -23,  -19,   19,   55,  -27],\n",
       "         [  34,   46,   67,   17,   -6],\n",
       "         [  36,   42,   10,   11,  -72]]],\n",
       "\n",
       "\n",
       "       [[[ -19,   -7,  -79, -100,    9],\n",
       "         [ -18,  -76,  -30,   58,   44],\n",
       "         [  -5,   44,  102,   86,   88],\n",
       "         [  -1,   65,   37,  -29,  -66],\n",
       "         [  -7,   21,  -83,  -17,  -63]]],\n",
       "\n",
       "\n",
       "       [[[ -32,   13,  -54,  -52,  -84],\n",
       "         [   2,   -7,  -16,  -93,  -45],\n",
       "         [  44,   69,  112,  -33,  -62],\n",
       "         [ -46,   80,   80,   77,   55],\n",
       "         [  -9,  -56,   31,   43,    2]]]], dtype=int16)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs256_quantize(torch.detach(model.conv1.weight).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[  12,   10,    2,   47,  -40],\n",
       "          [ -18,   62,  123,   90,   28],\n",
       "          [ -34,  -36,   51,   98,   37],\n",
       "          [ -66,  -86,  -77,   23,   23],\n",
       "          [ -83,  -86,  -53,  -49,    9]]],\n",
       " \n",
       " \n",
       "        [[[  75,   47,   67,   17,   32],\n",
       "          [  32,   82,   58,   35,   -1],\n",
       "          [  60,   30,   -5,    4,  -51],\n",
       "          [ -59,  -56,  -96,  -31,  -40],\n",
       "          [-127, -121,  -54,  -15,   43]]],\n",
       " \n",
       " \n",
       "        [[[ -11,  -75,   -4,   14,   70],\n",
       "          [ -81,  -36,  -30,   31,   76],\n",
       "          [ -44,  -62,   65,   60,   21],\n",
       "          [ -67,    0,   45,   92,  -21],\n",
       "          [  -2,  -33,   41,   33,  -43]]],\n",
       " \n",
       " \n",
       "        [[[  51,  -13,   -7,   47,   30],\n",
       "          [ -29,  -34,    9,   32,    3],\n",
       "          [ -20,  -16,   16,   47,  -23],\n",
       "          [  30,   39,   58,   15,   -5],\n",
       "          [  31,   36,    8,   10,  -62]]],\n",
       " \n",
       " \n",
       "        [[[ -16,   -6,  -68,  -86,    8],\n",
       "          [ -16,  -66,  -26,   50,   38],\n",
       "          [  -5,   38,   88,   74,   76],\n",
       "          [   0,   56,   32,  -25,  -57],\n",
       "          [  -6,   18,  -71,  -15,  -54]]],\n",
       " \n",
       " \n",
       "        [[[ -28,   11,  -47,  -44,  -73],\n",
       "          [   2,   -6,  -13,  -80,  -39],\n",
       "          [  38,   60,   97,  -28,  -54],\n",
       "          [ -39,   69,   69,   66,   48],\n",
       "          [  -7,  -48,   27,   37,    1]]]], dtype=int16),\n",
       " 220.90689559824614)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absmax_quantize(torch.detach(model.conv1.weight).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LeNet_quantize():\n",
    "    def __init__(self, conv_layer_1w:np.ndarray, conv_layer_1b:np.ndarray, \n",
    "                 conv_layer_2w:np.ndarray, conv_layer_2b:np.ndarray,\n",
    "                 dense_1_w:np.ndarray, dense_1_b:np.ndarray, \n",
    "                 dense_2_w:np.ndarray, dense_2_b:np.ndarray,\n",
    "                 dense_3_w:np.ndarray, dense_3_b:np.ndarray):\n",
    "        # 1 input image channel, 6 output channels, 5x5 square conv kernel\n",
    "        self.conv1 = self.Conv2d(1, 6, 5, conv_layer_1w, conv_layer_1b)\n",
    "        self.conv2 = self.Conv2d(6, 16, 5, conv_layer_2w, conv_layer_2b)\n",
    "        self.fc1 = self.myDense2d(dense_1_w, dense_1_b)\n",
    "        self.fc2 = self.myDense2d(dense_2_w, dense_2_b)\n",
    "        self.fc3 = self.myDense2d(dense_3_w, dense_3_b)\n",
    "    \n",
    "    def Conv2d(self, inChan:int, outChan:int, kernalDim:int, weight: np.ndarray, bias: np.ndarray):\n",
    "        myIn = inChan\n",
    "        myOt = outChan\n",
    "        myKr = kernalDim\n",
    "        myWeight = weight\n",
    "        myBias = bias\n",
    "\n",
    "        def CalConv2d(img:np.ndarray) -> np.ndarray:\n",
    "            inDim, imdim_r, imdim_c = img.shape\n",
    "            outImg = np.zeros((myOt, imdim_r-myKr, imdim_c-myKr))\n",
    "            for oc in range(myOt):\n",
    "                bias_s = myBias[oc]\n",
    "                for ic in range(myIn):\n",
    "                    kernal = myWeight[oc][ic]\n",
    "                    for kr_i in range(int(imdim_r-myKr)):\n",
    "                        for kr_j in range(int(imdim_c-myKr)):\n",
    "                            outImg[oc][kr_i][kr_j] += (kernal * img[ic][kr_i:kr_i+myKr,kr_j:kr_j+myKr]).sum() + bias_s\n",
    "            return outImg\n",
    "        return CalConv2d\n",
    "    \n",
    "    def myRelu(self, img:np.ndarray) -> np.ndarray:\n",
    "        return img.clip(0)\n",
    "    \n",
    "    def maxPool2d(self, img:np.ndarray) -> np.ndarray:\n",
    "        inDim, imdim_r, imdim_c = img.shape\n",
    "        outImg = np.zeros_like(img, shape=(inDim, int((imdim_r+1)/2), int((imdim_c+1)/2)))\n",
    "        for chn in range(inDim):\n",
    "            for i in range(int((imdim_r+1)/2)):\n",
    "                for j in range(int((imdim_c+1)/2)):\n",
    "                    if(i*2 > imdim_r):\n",
    "                        if(j*2 > imdim_c):\n",
    "                            outImg[chn][i,j] = img[chn][i*2,j*2]\n",
    "                        else:\n",
    "                            outImg[chn][i,j] = (img[chn][i*2,j*2:j*2+2]).max()\n",
    "                    else:\n",
    "                        if(j*2 > imdim_c):\n",
    "                            outImg[chn][i,j] = (img[chn][i*2:i*2+2,j*2]).max()\n",
    "                        else:\n",
    "                            outImg[chn][i,j] = (img[chn][i*2:i*2+2,j*2:j*2+2]).max()\n",
    "        return outImg\n",
    "\n",
    "    def myReshape(self, img:np.ndarray) -> np.ndarray:\n",
    "        return np.reshape(img, (img.size, -1))\n",
    "    \n",
    "    def myDense2d(self, weight:np.ndarray, bias:np.ndarray) -> np.ndarray:\n",
    "        myweight = weight\n",
    "        mybias  = bias\n",
    "\n",
    "        def dense(img:np.ndarray):\n",
    "            return np.dot(myweight, img) +  mybias\n",
    "\n",
    "        return dense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the weights and biases from the model and seperate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv1w = torch.detach(model.conv1.weight).numpy()\n",
    "cnv1b = torch.detach(model.conv1.bias).numpy()\n",
    "cnv2w = torch.detach(model.conv2.weight).numpy()\n",
    "cnv2b = torch.detach(model.conv2.bias).numpy()\n",
    "\n",
    "den1w = torch.detach(model.fc1.weight).numpy()\n",
    "den1b = np.reshape(torch.detach(model.fc1.bias).numpy(), (model.fc1.bias.size()[0], 1)) \n",
    "den2w = torch.detach(model.fc2.weight).numpy()\n",
    "den2b = np.reshape(torch.detach(model.fc2.bias).numpy(), (model.fc2.bias.size()[0], 1)) \n",
    "den3w = torch.detach(model.fc3.weight).numpy()\n",
    "den3b = np.reshape(torch.detach(model.fc3.bias).numpy(), (model.fc3.bias.size()[0], 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed scale (256) quantized weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnv1wq = fs256_quantize(torch.detach(model.conv1.weight).numpy())\n",
    "cnv1bq = fs256_quantize(torch.detach(model.conv1.bias).numpy())\n",
    "cnv2wq = fs256_quantize(torch.detach(model.conv2.weight).numpy())\n",
    "cnv2bq = fs256_quantize(torch.detach(model.conv2.bias).numpy())\n",
    "\n",
    "den1wq = fs256_quantize(torch.detach(model.fc1.weight).numpy())\n",
    "den1bq = fs256_quantize(np.reshape(torch.detach(model.fc1.bias).numpy(), (model.fc1.bias.size()[0], 1)) )\n",
    "den2wq = fs256_quantize(torch.detach(model.fc2.weight).numpy())\n",
    "den2bq = fs256_quantize(np.reshape(torch.detach(model.fc2.bias).numpy(), (model.fc2.bias.size()[0], 1)) )\n",
    "den3wq = fs256_quantize(torch.detach(model.fc3.weight).numpy())\n",
    "den3bq = fs256_quantize(np.reshape(torch.detach(model.fc3.bias).numpy(), (model.fc3.bias.size()[0], 1)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unquantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = LeNet_quantize(cnv1w, cnv1b, cnv2w, cnv2b, den1w, den1b, den2w, den2b, den3w, den3b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmq = LeNet_quantize(cnv1wq, cnv1bq, cnv2wq, cnv2bq, den1wq, den1bq, den2wq, den2bq, den3wq, den3bq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forward function LeNet class is copied here. \n",
    "- This is used to cross-validate the individual layer outputs with the unwraped LeNet_quantize class. Keep the required layer to cross-check and comment the other layers and check the output as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trch_forward(x):\n",
    "    x = F.max_pool2d(F.relu(F.conv2d(x, weight=model.conv1.weight, bias=model.conv1.bias)), (2, 2))\n",
    "    x = F.max_pool2d(F.relu(F.conv2d(x, weight=model.conv2.weight, bias=model.conv2.bias)), 2)\n",
    "    x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "    x = F.relu(F.linear(x, weight=model.fc1.weight, bias=model.fc1.bias))\n",
    "    x = F.relu(F.linear(x, weight=model.fc2.weight, bias=model.fc2.bias))\n",
    "    x = F.linear(x, weight=model.fc3.weight, bias=model.fc3.bias)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correspondencing unwraped function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_forward(x):\n",
    "    x = mm.maxPool2d(mm.myRelu(mm.conv1(x)))\n",
    "    x = mm.maxPool2d(mm.myRelu(mm.conv2(x)))\n",
    "    x = mm.myReshape(x)\n",
    "    x = mm.myRelu(mm.fc1(x))\n",
    "    x = mm.myRelu(mm.fc2(x))\n",
    "    x = mm.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correspondencing unwraped quantized function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_q_forward(x):\n",
    "    x = mmq.maxPool2d(mmq.myRelu(mmq.conv1(x)))\n",
    "    x = fs256_dequantize(x)\n",
    "    x = mmq.maxPool2d(mmq.myRelu(mmq.conv2(x)))\n",
    "    x = fs256_dequantize(x)\n",
    "    x = mmq.myReshape(x)\n",
    "    x = mmq.myRelu(mmq.fc1(x))\n",
    "    x = fs256_dequantize(x)\n",
    "    x = mmq.myRelu(mmq.fc2(x))\n",
    "    x = fs256_dequantize(x)\n",
    "    x = mmq.fc3(x)\n",
    "    x = fs256_dequantize(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 99.1 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = trch_forward(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate unwraped model\n",
    "\n",
    "> [Note] my_forward() function is incredibly slow compared to trch_forward()\n",
    "\n",
    "- Obs. my_forward does not support batch input hence the for loop.\n",
    "- Obs. a bit of accuracy drop due to no padding and other missing small fine tunes that present in Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.42 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    \n",
    "with torch.no_grad():\n",
    "      correct = 0\n",
    "      total = 0\n",
    "      for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = torch.zeros(images.shape[0])\n",
    "            for i in range(images.shape[0]):\n",
    "                  outputs[i] = np.argmax(my_forward(torch.Tensor.numpy(images[i])))\n",
    "            total += labels.size(0)\n",
    "            correct += (outputs == labels).sum().item()\n",
    "      print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate unwraped (FS) quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97.8 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "    \n",
    "with torch.no_grad():\n",
    "      correct = 0\n",
    "      total = 0\n",
    "      for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = torch.zeros(images.shape[0])\n",
    "            for i in range(images.shape[0]):\n",
    "                  outputs[i] = np.argmax(my_q_forward(torch.Tensor.numpy(images[i])))\n",
    "            total += labels.size(0)\n",
    "            correct += (outputs == labels).sum().item()\n",
    "      print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
